{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeJT_pt4S50P",
        "outputId": "95f34a18-dbf3-4770-d649-af79916b60bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pretty_midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyND5reHRY0_",
        "outputId": "69509613-aad6-4e80-c72b-6f18b2ef60cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.23.5)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.10/dist-packages (from mido>=1.1.16->pretty_midi) (23.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "nTF2IER4XMtS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some constants\n",
        "SEQUENCE_LENGTH = 100 # The length of the input sequence for the RNN\n",
        "BATCH_SIZE = 64 # The size of the mini-batch for training\n",
        "EPOCHS = 10 # The number of epochs for training\n",
        "EMBEDDING_DIM = 256 # The dimension of the embedding layer\n",
        "RNN_UNITS = 512 # The number of units in the RNN layer\n",
        "VOCAB_SIZE = 128 # The size of the vocabulary (number of MIDI notes)\n",
        "NO_NOTE = 128  # Symbol for \"no note\"\n",
        "\n",
        "# Define a function to load and preprocess the MIDI files\n",
        "def load_midi_files(path):\n",
        "  # Initialize an empty list to store the sequences\n",
        "  sequences = []\n",
        "  # Loop through all the files in the path\n",
        "  for file in os.listdir(path):\n",
        "    # Check if the file is a MIDI file\n",
        "    if file.endswith(\".mid\"):\n",
        "      # Load the MIDI file using pretty_midi\n",
        "      midi = pretty_midi.PrettyMIDI(os.path.join(path, file))\n",
        "      # Get the list of notes played in the MIDI file\n",
        "      notes = [note.pitch for note in midi.instruments[0].notes]\n",
        "      # Reshape the list of notes to create sub-sequences of length SEQUENCE_LENGTH\n",
        "      num_sequences = len(notes) // SEQUENCE_LENGTH\n",
        "      reshaped_notes = np.array(notes[:num_sequences * SEQUENCE_LENGTH])\n",
        "      reshaped_notes = reshaped_notes.reshape(-1, SEQUENCE_LENGTH)\n",
        "      # Append the sub-sequences to the list of sequences\n",
        "      sequences.append(reshaped_notes)\n",
        "  # Concatenate all the sub-sequences into one array\n",
        "  sequences = np.concatenate(sequences, axis=0)\n",
        "  # Pad the sequences with the symbol for \"no note\"\n",
        "  sequences = pad_sequences(sequences, maxlen=SEQUENCE_LENGTH, value=NO_NOTE)\n",
        "  # Return the array of sequences\n",
        "  return sequences\n",
        "\n",
        "# Path to your MIDI files\n",
        "path_to_midi_files = \"/content/drive/MyDrive/generate_audio/audio_files\"\n",
        "\n",
        "# Load the MIDI files\n",
        "sequences = load_midi_files(path_to_midi_files)\n",
        "\n",
        "# Split the sequences into training and validation sets\n",
        "train_sequences, val_sequences = train_test_split(sequences, test_size=0.2)\n",
        "\n",
        "# Define a function to create and compile the RNN model\n",
        "def create_model(vocab_size, embedding_dim, rnn_units):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Embedding(vocab_size + 1, embedding_dim))  # Add 1 to vocab_size because we added an extra symbol for \"no note\"\n",
        "  model.add(layers.LSTM(rnn_units, return_sequences=True))\n",
        "  model.add(layers.Dense(vocab_size + 1, activation=\"softmax\"))  # Add 1 to vocab_size because we added an extra symbol for \"no note\"\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "# Create and compile the RNN model using the defined constants\n",
        "model = create_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS)\n",
        "\n",
        "# Train the model on the training data for EPOCHS epochs and validate on the validation data\n",
        "model.fit(train_sequences, train_sequences, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(val_sequences, val_sequences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVfko6T1blIl",
        "outputId": "56eb0cc4-de45-4591-f1c5-4a1593f0943a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 12s 3s/step - loss: 4.7985 - accuracy: 0.2622 - val_loss: 4.4109 - val_accuracy: 0.2277\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 4.3617 - accuracy: 0.1912 - val_loss: 4.0506 - val_accuracy: 0.1377\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 9s 2s/step - loss: 3.8243 - accuracy: 0.1890 - val_loss: 3.6926 - val_accuracy: 0.1836\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 3.5103 - accuracy: 0.2378 - val_loss: 3.4031 - val_accuracy: 0.2416\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 9s 2s/step - loss: 3.3466 - accuracy: 0.2753 - val_loss: 3.3617 - val_accuracy: 0.1913\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 10s 3s/step - loss: 3.2459 - accuracy: 0.2362 - val_loss: 3.2450 - val_accuracy: 0.3080\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 3.1515 - accuracy: 0.2899 - val_loss: 3.1867 - val_accuracy: 0.2638\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 10s 3s/step - loss: 3.0833 - accuracy: 0.2750 - val_loss: 3.1300 - val_accuracy: 0.2431\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 10s 3s/step - loss: 3.0988 - accuracy: 0.2706 - val_loss: 3.0887 - val_accuracy: 0.3541\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 9s 2s/step - loss: 3.0054 - accuracy: 0.3640 - val_loss: 3.0819 - val_accuracy: 0.3775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ab71b98cc40>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_music(model, seed, num_notes):\n",
        "  # Initialize an empty list to store the generated notes\n",
        "  generated_notes = []\n",
        "  # Loop for num_notes times\n",
        "  for i in range(num_notes):\n",
        "    # Predict the next note using the model and the seed sequence\n",
        "    prediction = model.predict(seed)\n",
        "    # Sample a note from the prediction using a multinomial distribution\n",
        "    note = np.random.choice(range(VOCAB_SIZE + 1), p=prediction[0][-1])\n",
        "    # Append the note to the list of generated notes\n",
        "    generated_notes.append(note)\n",
        "    # Update the seed sequence by appending the note and removing the first element\n",
        "    seed = np.append(seed[:, 1:], [[note]], axis=1)\n",
        "  # Return the array of generated notes\n",
        "  return np.array(generated_notes)\n",
        "\n",
        "# Generate new music using the trained model and a random seed sequence from the validation data\n",
        "seed = val_sequences[np.random.randint(0, len(val_sequences))]\n",
        "seed = seed.reshape(1, SEQUENCE_LENGTH)  # Reshape the seed sequence to have shape (1, SEQUENCE_LENGTH)\n",
        "generated_notes = generate_music(model, seed, 1000)\n"
      ],
      "metadata": {
        "id": "ROG1CFe1chcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install MIDIUtil"
      ],
      "metadata": {
        "id": "LKa85pcGhjKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da023cf-0cf8-46ae-8252-43a0d66ef402"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MIDIUtil\n",
            "  Downloading MIDIUtil-1.2.1.tar.gz (1.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: MIDIUtil\n",
            "  Building wheel for MIDIUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MIDIUtil: filename=MIDIUtil-1.2.1-py3-none-any.whl size=54570 sha256=cc0af5cb17d99ea38e32bda59f53a1d4aaf4179c534ca6c03bc3b479c77898c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/43/4a/00b5e4f2fe5e2cd6e92b461995a3a97a2cebb30ab5783501b0\n",
            "Successfully built MIDIUtil\n",
            "Installing collected packages: MIDIUtil\n",
            "Successfully installed MIDIUtil-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from midiutil import MIDIFile\n",
        "from google.colab import files\n",
        "from music21 import note, chord, instrument, stream"
      ],
      "metadata": {
        "id": "imKdfOCNhoWH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_music_midi(generated_notes):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "    for pattern in generated_notes:\n",
        "        # assuming pattern is an integer\n",
        "        new_note = note.Note(int(pattern))\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "        # Increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='generated_music.mid')\n",
        "\n",
        "# Generate new music using the trained model and a random seed sequence from the validation data\n",
        "seed = val_sequences[np.random.randint(0, len(val_sequences))]\n",
        "seed = seed.reshape(1, SEQUENCE_LENGTH)  # Reshape the seed sequence to have shape (1, SEQUENCE_LENGTH)\n",
        "generated_notes = generate_music(model, seed, 1000)\n",
        "\n",
        "# Convert the generated notes to a MIDI file and save it\n",
        "generate_music_midi(generated_notes)\n"
      ],
      "metadata": {
        "id": "57NZqVkSguRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}